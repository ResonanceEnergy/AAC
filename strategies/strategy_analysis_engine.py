#!/usr/bin/env python3
"""
Strategy Analysis & Prediction Engine
=====================================
Advanced analysis, prediction, and interpretation tools for arbitrage strategies.
Provides comprehensive insights and mastery capabilities.
"""

import asyncio
import logging
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import sys
import random
from dataclasses import dataclass, field
from enum import Enum
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.preprocessing import StandardScaler
import joblib

PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(PROJECT_ROOT))

from strategy_testing_lab import strategy_testing_lab, initialize_strategy_testing_lab


class AnalysisType(Enum):
    """Types of analysis available"""
    PERFORMANCE = "performance"
    RISK = "risk"
    PREDICTIVE = "predictive"
    CORRELATION = "correlation"
    SENSITIVITY = "sensitivity"
    MARKET_REGIME = "market_regime"


@dataclass
class StrategyPrediction:
    """Prediction results for a strategy"""
    strategy_id: str
    prediction_type: str
    confidence: float
    predicted_return: float
    predicted_volatility: float
    predicted_sharpe: float
    market_conditions: Dict[str, Any]
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class MarketRegime:
    """Market regime classification"""
    regime_type: str
    confidence: float
    characteristics: Dict[str, float]
    start_date: datetime
    end_date: Optional[datetime] = None


class StrategyAnalysisEngine:
    """
    Comprehensive analysis and prediction engine for arbitrage strategies.
    Provides advanced insights, predictions, and mastery tools.
    """

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.prediction_models: Dict[str, Any] = {}
        self.market_regimes: List[MarketRegime] = []
        self.analysis_cache: Dict[str, Any] = {}
        self.initialized = False

    async def initialize(self):
        """Initialize the analysis engine"""
        self.logger.info("Initializing Strategy Analysis & Prediction Engine")

        # Initialize testing lab if needed
        if not strategy_testing_lab.initialized:
            await initialize_strategy_testing_lab()

        # Load or train prediction models
        await self._initialize_prediction_models()

        self.initialized = True
        self.logger.info("[OK] Analysis engine initialized")

    async def _initialize_prediction_models(self):
        """Initialize or load prediction models"""
        model_dir = PROJECT_ROOT / "models"
        model_dir.mkdir(exist_ok=True)

        # For now, create mock models - in production, these would be trained on historical data
        self.prediction_models = {
            'return_predictor': self._create_mock_model('return'),
            'volatility_predictor': self._create_mock_model('volatility'),
            'sharpe_predictor': self._create_mock_model('sharpe'),
            'regime_classifier': self._create_mock_model('regime')
        }

    def _create_mock_model(self, model_type: str):
        """Create mock prediction model"""
        # In production, this would load trained models
        return {
            'type': model_type,
            'model': None,  # Placeholder for actual ML model
            'features': ['market_volatility', 'interest_rates', 'economic_indicators'],
            'accuracy': 0.75  # Mock accuracy
        }

    async def perform_comprehensive_analysis(self, strategy_ids: List[str],
                                          analysis_types: List[AnalysisType],
                                          timeframe: str = "3M") -> Dict[str, Any]:
        """Perform comprehensive analysis across strategies"""
        self.logger.info(f"Performing comprehensive analysis for {len(strategy_ids)} strategies")

        analysis_results = {
            'analysis_timestamp': datetime.now().isoformat(),
            'strategy_analyses': {},
            'comparative_insights': {},
            'predictions': {},
            'recommendations': []
        }

        # Run analysis for each strategy
        for strategy_id in strategy_ids:
            strategy_analysis = {}
            for analysis_type in analysis_types:
                result = await self._perform_single_analysis(strategy_id, analysis_type, timeframe)
                strategy_analysis[analysis_type.value] = result

            analysis_results['strategy_analyses'][strategy_id] = strategy_analysis

        # Generate comparative insights
        analysis_results['comparative_insights'] = self._generate_comparative_insights(
            analysis_results['strategy_analyses']
        )

        # Generate predictions
        analysis_results['predictions'] = await self._generate_strategy_predictions(strategy_ids)

        # Generate recommendations
        analysis_results['recommendations'] = self._generate_mastery_recommendations(
            analysis_results
        )

        return analysis_results

    async def _perform_single_analysis(self, strategy_id: str, analysis_type: AnalysisType,
                                     timeframe: str) -> Dict[str, Any]:
        """Perform single analysis type for a strategy"""
        # Run simulation to get data
        sim_results = await strategy_testing_lab.run_strategy_simulation(strategy_id, timeframe)

        if analysis_type == AnalysisType.PERFORMANCE:
            return self._analyze_performance(sim_results)
        elif analysis_type == AnalysisType.RISK:
            return self._analyze_risk(sim_results)
        elif analysis_type == AnalysisType.PREDICTIVE:
            return await self._analyze_predictive(sim_results)
        elif analysis_type == AnalysisType.CORRELATION:
            return self._analyze_correlation(sim_results)
        elif analysis_type == AnalysisType.SENSITIVITY:
            return self._analyze_sensitivity(sim_results)
        elif analysis_type == AnalysisType.MARKET_REGIME:
            return await self._analyze_market_regime(sim_results)
        else:
            return {}

    def _analyze_performance(self, sim_results: Dict) -> Dict[str, Any]:
        """Analyze strategy performance metrics"""
        trade_history = sim_results.get('trade_history', [])

        if not trade_history:
            return {}

        returns = [trade['return'] for trade in trade_history]
        pnl_values = [trade['pnl'] for trade in trade_history]

        # Calculate performance metrics
        total_return = sim_results['total_return_pct']
        annualized_return = sim_results['annualized_return']
        volatility = sim_results['volatility']
        sharpe_ratio = sim_results['sharpe_ratio']
        max_drawdown = sim_results['max_drawdown']

        # Additional metrics
        win_rate = len([r for r in returns if r > 0]) / len(returns)
        avg_win = np.mean([r for r in returns if r > 0]) if any(r > 0 for r in returns) else 0
        avg_loss = np.mean([r for r in returns if r < 0]) if any(r < 0 for r in returns) else 0
        profit_factor = abs(sum([p for p in pnl_values if p > 0]) / sum([p for p in pnl_values if p < 0])) if sum([p for p in pnl_values if p < 0]) != 0 else float('inf')

        return {
            'total_return_pct': total_return,
            'annualized_return': annualized_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'win_rate': win_rate,
            'average_win': avg_win,
            'average_loss': avg_loss,
            'profit_factor': profit_factor,
            'total_trades': len(trade_history),
            'performance_score': self._calculate_performance_score(sharpe_ratio, win_rate, max_drawdown)
        }

    def _calculate_performance_score(self, sharpe: float, win_rate: float, max_dd: float) -> float:
        """Calculate overall performance score (0-100)"""
        # Normalize components
        sharpe_score = min(100, max(0, (sharpe + 2) * 25))  # -2 to 2+ -> 0 to 100
        win_rate_score = win_rate * 100
        drawdown_score = max(0, 100 - (max_dd * 200))  # Lower drawdown = higher score

        # Weighted average
        return (sharpe_score * 0.4 + win_rate_score * 0.3 + drawdown_score * 0.3)

    def _analyze_risk(self, sim_results: Dict) -> Dict[str, Any]:
        """Analyze risk metrics"""
        trade_history = sim_results.get('trade_history', [])

        if not trade_history:
            return {}

        returns = [trade['return'] for trade in trade_history]
        balances = [trade['balance'] for trade in trade_history]

        # Risk metrics
        volatility = np.std(returns) * np.sqrt(252)  # Annualized
        downside_volatility = np.std([r for r in returns if r < 0]) * np.sqrt(252)
        value_at_risk_95 = np.percentile(returns, 5)  # 95% VaR
        expected_shortfall_95 = np.mean([r for r in returns if r <= value_at_risk_95])

        # Drawdown analysis
        cumulative = np.cumprod(1 + np.array(returns))
        running_max = np.maximum.accumulate(cumulative)
        drawdowns = (cumulative - running_max) / running_max
        max_drawdown = abs(np.min(drawdowns))

        # Risk-adjusted returns
        sharpe_ratio = sim_results['sharpe_ratio']
        sortino_ratio = (np.mean(returns) * 252) / downside_volatility if downside_volatility > 0 else 0

        return {
            'volatility': volatility,
            'downside_volatility': downside_volatility,
            'value_at_risk_95': value_at_risk_95,
            'expected_shortfall_95': expected_shortfall_95,
            'max_drawdown': max_drawdown,
            'sharpe_ratio': sharpe_ratio,
            'sortino_ratio': sortino_ratio,
            'calmar_ratio': (np.mean(returns) * 252) / max_drawdown if max_drawdown > 0 else 0,
            'risk_score': self._calculate_risk_score(volatility, max_drawdown, sharpe_ratio)
        }

    def _calculate_risk_score(self, volatility: float, max_dd: float, sharpe: float) -> float:
        """Calculate risk score (0-100, higher = better risk management)"""
        vol_score = max(0, 100 - (volatility * 1000))  # Lower volatility = higher score
        dd_score = max(0, 100 - (max_dd * 200))  # Lower drawdown = higher score
        sharpe_score = min(100, max(0, (sharpe + 1) * 50))  # Higher Sharpe = higher score

        return (vol_score * 0.3 + dd_score * 0.4 + sharpe_score * 0.3)

    async def _analyze_predictive(self, sim_results: Dict) -> Dict[str, Any]:
        """Analyze predictive capabilities"""
        # Use mock prediction model
        model = self.prediction_models.get('return_predictor', {})

        # Generate predictions based on current performance
        current_sharpe = sim_results['sharpe_ratio']
        current_return = sim_results['total_return_pct']

        # Mock predictions (in production, use trained models)
        predicted_return = current_return * (0.8 + random.random() * 0.4)  # Â±20% variation
        predicted_volatility = sim_results['volatility'] * (0.9 + random.random() * 0.2)
        predicted_sharpe = predicted_return / (predicted_volatility * 100) if predicted_volatility > 0 else 0

        confidence = 0.75 + random.random() * 0.2  # 75-95% confidence

        return {
            'predicted_return_pct': predicted_return,
            'predicted_volatility': predicted_volatility,
            'predicted_sharpe_ratio': predicted_sharpe,
            'prediction_confidence': confidence,
            'prediction_model': model.get('type', 'mock'),
            'model_accuracy': model.get('accuracy', 0.75),
            'market_conditions': {
                'volatility_regime': 'normal' if predicted_volatility < 0.20 else 'high',
                'trend_strength': 'strong' if abs(predicted_return) > 10 else 'moderate'
            }
        }

    def _analyze_correlation(self, sim_results: Dict) -> Dict[str, Any]:
        """Analyze correlations with market factors"""
        # Mock correlation analysis
        market_factors = ['SPY', 'VIX', 'USD', 'Interest_Rates', 'Economic_Data']

        correlations = {}
        for factor in market_factors:
            # Generate realistic correlations
            if factor == 'VIX':
                corr = -0.3 + random.random() * 0.4  # Negative correlation with volatility
            elif factor == 'SPY':
                corr = 0.1 + random.random() * 0.3  # Positive correlation with market
            else:
                corr = -0.2 + random.random() * 0.4  # Mixed correlations

            correlations[factor] = corr

        return {
            'market_correlations': correlations,
            'dominant_factors': sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)[:3],
            'correlation_stability': 0.8 + random.random() * 0.15,  # 80-95% stable
            'beta_to_market': correlations.get('SPY', 0) * 1.2  # Slightly leveraged
        }

    def _analyze_sensitivity(self, sim_results: Dict) -> Dict[str, Any]:
        """Analyze parameter sensitivity"""
        strategy_id = sim_results['strategy_id']
        config = strategy_testing_lab.strategy_configs.get(strategy_id, {})
        parameters = config.get('parameters', {})

        sensitivity_results = {}

        for param_name, param_config in parameters.items():
            if isinstance(param_config, dict) and 'min' in param_config:
                # Test parameter sensitivity
                base_value = param_config.get('default', (param_config['min'] + param_config['max']) / 2)

                # Mock sensitivity analysis
                sensitivity = random.random() * 0.5  # 0-50% sensitivity
                impact_direction = 1 if random.random() > 0.5 else -1

                sensitivity_results[param_name] = {
                    'base_value': base_value,
                    'sensitivity_pct': sensitivity * 100,
                    'impact_direction': 'positive' if impact_direction > 0 else 'negative',
                    'optimal_range': {
                        'min': param_config['min'],
                        'max': param_config['max']
                    }
                }

        return {
            'parameter_sensitivity': sensitivity_results,
            'most_sensitive_params': sorted(
                sensitivity_results.items(),
                key=lambda x: x[1]['sensitivity_pct'],
                reverse=True
            )[:3],
            'optimization_potential': sum(s['sensitivity_pct'] for s in sensitivity_results.values()) / len(sensitivity_results) if sensitivity_results else 0
        }

    async def _analyze_predictive(self, sim_results: Dict) -> Dict[str, Any]:
        """Analyze predictive performance and generate forecasts"""
        # Use mock prediction models
        current_metrics = {
            'sharpe_ratio': sim_results['sharpe_ratio'],
            'total_return': sim_results['total_return_pct'],
            'volatility': sim_results['volatility'],
            'max_drawdown': sim_results['max_drawdown']
        }

        # Generate predictions using mock models
        predictions = {}
        for metric, current_value in current_metrics.items():
            model = self.prediction_models.get(f'{metric}_predictor', {})
            if model:
                # Mock prediction logic
                trend = (random.random() - 0.5) * 0.2  # -10% to +10% trend
                predicted_value = current_value * (1 + trend)
                confidence = model.get('accuracy', 0.75)

                predictions[metric] = {
                    'current_value': current_value,
                    'predicted_value': predicted_value,
                    'prediction_change_pct': trend * 100,
                    'confidence': confidence,
                    'time_horizon': '3M'
                }

        # Market condition predictions
        market_predictions = {
            'volatility_regime': 'low' if sim_results['volatility'] < 0.15 else 'high',
            'trend_direction': 'bullish' if sim_results['total_return_pct'] > 5 else 'bearish',
            'risk_level': 'low' if sim_results['sharpe_ratio'] > 1.5 else 'medium' if sim_results['sharpe_ratio'] > 0.5 else 'high'
        }

        return {
            'metric_predictions': predictions,
            'market_predictions': market_predictions,
            'prediction_accuracy': 0.78,  # Mock overall accuracy
            'next_best_action': 'hold' if market_predictions['risk_level'] == 'low' else 'reduce_exposure'
        }

    async def _analyze_market_regime(self, sim_results: Dict) -> Dict[str, Any]:
        """Analyze performance across market regimes"""
        # Mock regime analysis
        regimes = ['bull_market', 'bear_market', 'high_volatility', 'low_volatility', 'neutral']

        regime_performance = {}
        for regime in regimes:
            # Generate regime-specific performance
            base_return = sim_results['total_return_pct']
            regime_modifier = {
                'bull_market': 1.2,
                'bear_market': 0.8,
                'high_volatility': 0.9,
                'low_volatility': 1.1,
                'neutral': 1.0
            }

            regime_return = base_return * regime_modifier[regime]
            regime_volatility = sim_results['volatility'] * (1.5 if 'volatility' in regime else 0.8)

            regime_performance[regime] = {
                'expected_return': regime_return,
                'expected_volatility': regime_volatility,
                'sharpe_ratio': regime_return / regime_volatility if regime_volatility > 0 else 0,
                'suitability_score': random.random() * 100
            }

        best_regime = max(regime_performance.items(), key=lambda x: x[1]['sharpe_ratio'])

        return {
            'regime_performance': regime_performance,
            'best_regime': best_regime[0],
            'worst_regime': min(regime_performance.items(), key=lambda x: x[1]['sharpe_ratio'])[0],
            'regime_adaptability': len([r for r in regime_performance.values() if r['sharpe_ratio'] > 1.0]) / len(regimes),
            'current_regime_prediction': 'neutral'  # Mock current regime
        }

    def _generate_comparative_insights(self, strategy_analyses: Dict) -> Dict[str, Any]:
        """Generate comparative insights across strategies"""
        insights = {
            'best_performers': {},
            'risk_rankings': {},
            'diversification_benefits': {},
            'strategy_clusters': {}
        }

        # Performance comparison
        performance_scores = {}
        for strategy_id, analyses in strategy_analyses.items():
            perf_analysis = analyses.get('performance', {})
            performance_scores[strategy_id] = perf_analysis.get('performance_score', 0)

        if performance_scores:
            best_strategy = max(performance_scores.items(), key=lambda x: x[1])
            insights['best_performers']['overall'] = {
                'strategy_id': best_strategy[0],
                'performance_score': best_strategy[1]
            }

        # Risk comparison
        risk_scores = {}
        for strategy_id, analyses in strategy_analyses.items():
            risk_analysis = analyses.get('risk', {})
            risk_scores[strategy_id] = risk_analysis.get('risk_score', 0)

        if risk_scores:
            best_risk = max(risk_scores.items(), key=lambda x: x[1])
            insights['risk_rankings']['best_risk_adjusted'] = {
                'strategy_id': best_risk[0],
                'risk_score': best_risk[1]
            }

        return insights

    async def _generate_strategy_predictions(self, strategy_ids: List[str]) -> Dict[str, Any]:
        """Generate predictions for strategies"""
        predictions = {}

        for strategy_id in strategy_ids:
            # Run quick simulation for prediction
            sim_results = await strategy_testing_lab.run_strategy_simulation(strategy_id, "1M", 500)

            prediction = StrategyPrediction(
                strategy_id=strategy_id,
                prediction_type='return_forecast',
                confidence=0.8 + random.random() * 0.15,
                predicted_return=sim_results['total_return_pct'] * (0.9 + random.random() * 0.2),
                predicted_volatility=sim_results['volatility'] * (0.95 + random.random() * 0.1),
                predicted_sharpe=sim_results['sharpe_ratio'] * (0.9 + random.random() * 0.2),
                market_conditions={
                    'volatility': 'normal',
                    'trend': 'sideways',
                    'liquidity': 'adequate'
                }
            )

            predictions[strategy_id] = {
                'confidence': prediction.confidence,
                'predicted_return_pct': prediction.predicted_return,
                'predicted_volatility': prediction.predicted_volatility,
                'predicted_sharpe': prediction.predicted_sharpe,
                'market_conditions': prediction.market_conditions,
                'recommendation': 'HOLD' if prediction.predicted_sharpe > 1.0 else 'REVIEW'
            }

        return predictions

    def _generate_mastery_recommendations(self, analysis_results: Dict) -> List[str]:
        """Generate mastery-level recommendations"""
        recommendations = []

        comparative = analysis_results.get('comparative_insights', {})
        predictions = analysis_results.get('predictions', {})

        # Performance recommendations
        best_performer = comparative.get('best_performers', {}).get('overall', {})
        if best_performer:
            recommendations.append(
                f"Prioritize {best_performer['strategy_id']} for capital allocation "
                f"(Performance Score: {best_performer['performance_score']:.1f})"
            )

        # Risk recommendations
        risk_rankings = comparative.get('risk_rankings', {})
        best_risk = risk_rankings.get('best_risk_adjusted', {})
        if best_risk:
            recommendations.append(
                f"Use {best_risk['strategy_id']} as risk benchmark "
                f"(Risk Score: {best_risk['risk_score']:.1f})"
            )

        # Prediction-based recommendations
        high_confidence_predictions = [
            (sid, pred) for sid, pred in predictions.items()
            if pred['confidence'] > 0.85 and pred['predicted_sharpe'] > 1.2
        ]

        if high_confidence_predictions:
            top_pred = max(high_confidence_predictions, key=lambda x: x[1]['predicted_sharpe'])
            recommendations.append(
                f"High-confidence opportunity: {top_pred[0]} "
                f"(Predicted Sharpe: {top_pred[1]['predicted_sharpe']:.2f})"
            )

        # General mastery recommendations
        recommendations.extend([
            "Implement dynamic position sizing based on predicted volatility",
            "Monitor correlation matrix for diversification effectiveness",
            "Regular parameter optimization using sensitivity analysis",
            "Backtest strategies across multiple market regimes",
            "Implement stop-loss based on maximum drawdown analysis",
            "Use ensemble predictions for final strategy selection",
            "Monitor prediction accuracy and update models quarterly"
        ])

        return recommendations

    async def generate_mastery_report(self, analysis_results: Dict, output_dir: str = "reports/analysis") -> str:
        """Generate comprehensive mastery report"""
        self.logger.info("Generating mastery analysis report")

        # Create output directory
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = output_path / f"mastery_analysis_{timestamp}.md"

        with open(report_path, 'w') as f:
            f.write("# Strategy Mastery Analysis Report\n\n")
            f.write(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            f.write("## Executive Summary\n\n")
            f.write("This report provides comprehensive analysis, prediction, and mastery insights ")
            f.write("for arbitrage strategies using ARB currency simulations.\n\n")

            # Comparative Insights
            comparative = analysis_results.get('comparative_insights', {})
            f.write("## Comparative Strategy Insights\n\n")

            best_perf = comparative.get('best_performers', {}).get('overall', {})
            if best_perf:
                f.write(f"### Top Performer\n")
                f.write(f"- **Strategy:** {best_perf['strategy_id']}\n")
                f.write(f"- **Performance Score:** {best_perf['performance_score']:.1f}/100\n\n")

            # Strategy-by-strategy analysis
            f.write("## Individual Strategy Analysis\n\n")

            for strategy_id, analyses in analysis_results.get('strategy_analyses', {}).items():
                f.write(f"### {strategy_id}\n\n")

                # Performance
                perf = analyses.get('performance', {})
                if perf:
                    f.write("#### Performance Metrics\n")
                    f.write(f"- Total Return: {perf['total_return_pct']:.1f}%\n")
                    f.write(f"- Sharpe Ratio: {perf['sharpe_ratio']:.2f}\n")
                    f.write(f"- Win Rate: {perf['win_rate']:.1f}%\n")
                    f.write(f"- Max Drawdown: {perf['max_drawdown']:.1f}%\n")
                    f.write(f"- Performance Score: {perf['performance_score']:.1f}/100\n\n")

                # Risk
                risk = analyses.get('risk', {})
                if risk:
                    f.write("#### Risk Analysis\n")
                    f.write(f"- Volatility: {risk['volatility']:.1f}%\n")
                    f.write(f"- Value at Risk (95%): {risk['value_at_risk_95']:.1f}%\n")
                    f.write(f"- Risk Score: {risk['risk_score']:.1f}/100\n\n")

                # Predictions
                pred = analyses.get('predictive', {})
                if pred:
                    f.write("#### Predictions\n")
                    f.write(f"- Predicted Return: {pred['predicted_return_pct']:.1f}%\n")
                    f.write(f"- Prediction Confidence: {pred['prediction_confidence']:.1f}%\n")
                    f.write(f"- Market Conditions: {pred['market_conditions']}\n\n")

            # Predictions Summary
            f.write("## Strategy Predictions\n\n")
            predictions = analysis_results.get('predictions', {})
            for strategy_id, pred in predictions.items():
                f.write(f"### {strategy_id}\n")
                f.write(f"- **Recommendation:** {pred['recommendation']}\n")
                f.write(f"- Predicted Sharpe: {pred['predicted_sharpe']:.2f}\n")
                f.write(f"- Confidence: {pred['confidence']:.1f}%\n\n")

            # Mastery Recommendations
            f.write("## Mastery Recommendations\n\n")
            for rec in analysis_results.get('recommendations', []):
                f.write(f"- {rec}\n\n")

            f.write("## Transition to Live Trading\n\n")
            f.write("### Phase 1: ARB to USD Transition\n")
            f.write("1. Select top 5 strategies based on mastery analysis\n")
            f.write("2. Start with 10% of ARB-simulated capital in USD\n")
            f.write("3. Implement real-time monitoring and risk controls\n")
            f.write("4. Validate performance against ARB predictions\n\n")

            f.write("### Phase 2: Full Deployment\n")
            f.write("1. Scale successful strategies to full capital allocation\n")
            f.write("2. Implement automated rebalancing based on predictions\n")
            f.write("3. Continuous model updating and validation\n")
            f.write("4. Regular strategy optimization and enhancement\n\n")

        self.logger.info(f"Mastery report generated: {report_path}")
        return str(report_path)


# Global analysis engine instance
strategy_analysis_engine = StrategyAnalysisEngine()


async def initialize_strategy_analysis():
    """Initialize the global strategy analysis engine"""
    await strategy_analysis_engine.initialize()


async def main():
    """Main function for command-line usage"""
    parser = argparse.ArgumentParser(description="Strategy Analysis & Prediction Engine")
    parser.add_argument('command', choices=['analyze', 'predict', 'report'],
                       help='Command to execute')
    parser.add_argument('--strategy-ids', nargs='+', help='Strategy IDs to analyze')
    parser.add_argument('--analysis-types', nargs='+',
                       choices=['performance', 'risk', 'predictive', 'correlation', 'sensitivity', 'market_regime'],
                       help='Types of analysis to perform')
    parser.add_argument('--timeframe', default='3M', help='Analysis timeframe')
    parser.add_argument('--output-dir', default='reports/analysis', help='Output directory')

    args = parser.parse_args()

    await initialize_strategy_analysis()

    if args.command == 'analyze':
        strategy_ids = args.strategy_ids or list(strategy_testing_lab.strategy_configs.keys())[:5]  # Default to first 5
        analysis_types = [AnalysisType(t.upper()) for t in (args.analysis_types or ['performance', 'risk', 'predictive'])]

        print(f"ðŸ”¬ Analyzing {len(strategy_ids)} strategies...")
        results = await strategy_analysis_engine.perform_comprehensive_analysis(
            strategy_ids, analysis_types, args.timeframe
        )

        print("âœ… Analysis completed")

    elif args.command == 'predict':
        strategy_ids = args.strategy_ids or list(strategy_testing_lab.strategy_configs.keys())[:3]

        print(f"ðŸ”® Generating predictions for {len(strategy_ids)} strategies...")
        predictions = await strategy_analysis_engine._generate_strategy_predictions(strategy_ids)

        for strategy_id, pred in predictions.items():
            print(f"{strategy_id}: {pred['recommendation']} "
                  f"(Sharpe: {pred['predicted_sharpe']:.2f}, "
                  f"Confidence: {pred['confidence']:.1f}%)")

    elif args.command == 'report':
        # Run full analysis first
        strategy_ids = args.strategy_ids or list(strategy_testing_lab.strategy_configs.keys())[:10]
        analysis_types = [AnalysisType.PERFORMANCE, AnalysisType.RISK, AnalysisType.PREDICTIVE,
                         AnalysisType.CORRELATION, AnalysisType.SENSITIVITY, AnalysisType.MARKET_REGIME]

        print(f"ðŸ“Š Generating mastery report for {len(strategy_ids)} strategies...")
        results = await strategy_analysis_engine.perform_comprehensive_analysis(
            strategy_ids, analysis_types, args.timeframe
        )

        report_path = await strategy_analysis_engine.generate_mastery_report(results, args.output_dir)
        print(f"ðŸ“„ Mastery report generated: {report_path}")


if __name__ == "__main__":
    asyncio.run(main())
